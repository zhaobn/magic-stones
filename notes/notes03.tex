% Created: 2019-10-31
% Third draft of normative models for the magic stones task
% http://github.com/zhaobn/magic_stones
% Main changes: 

\documentclass{article}
\title{
	[Magic Stones] Normative Models Draft \\
	\large Working Title:
	Theory formation in dynamic causal generalization
	%Old: Category Bias in Dynamic Causal Generalization
}
\author{
	Bonan Zhao\\
	b.zhao@ed.ac.uk
}


% Text formats: margin, font, spacing
\usepackage[margin=0.8in]{geometry}
\usepackage{charter}
\renewcommand{\baselinestretch}{1.3}

% Shorthands
\newcommand{\featurespace}{F}
\newcommand{\colorspace}{\mathbb{CL}}
\newcommand{\shapespace}{\mathbb{SP}}

% Math stuff
\usepackage{amsmath}
\usepackage{amsfonts}
\newcommand\numberthis{\addtocounter{equation}{1}\tag{\theequation}}

% Settings for drawings
\usepackage{tikz,wrapfig}
\usetikzlibrary{shapes.geometric, arrows}

% Table packages
\usepackage{multirow}

\begin{document}
\maketitle

\section{Models}

\subsection*{Task formalization}

A magic stone $g$ is formalized as an expression $g = c_g \wedge s_g$, 
where its color $c_g$ takes value from a finite color space $\colorspace=\{red, yellow, blue\}$, 
and its shape $s_g$ takes value from a finite shape space $\shapespace=\{round, circle, triangle\}$.
In total, the set of all magic stones $G$ is of size $(|\colorspace| \times |\shapespace|) = 9$.


% Figure of a task formalization
\tikzstyle{node} = [circle, minimum width=0.8cm, minimum height=0.8cm, text centered, draw=black]
\tikzstyle{arrow} = [thick,->,>=stealth]
\begin{wrapfigure}{l}{0.35\textwidth}
\begin{center}
	\begin{tikzpicture}
		\node (a) [node] {$A$};
		\node (r) [node, right of=a, xshift=0.8cm] {$R$};
		\node (rp) [node, below right of=a, yshift=-0.5cm, xshift=0.2cm] {$R'$};
		\draw [arrow] (a) -- (rp);
		\draw [arrow] (r) -- (rp);
	\end{tikzpicture}
	\caption{A magic stone task.}
	\label{model}
\end{center}
\end{wrapfigure}


A magic stone task consists of an agent stone $A$ that changes the recipient stone $R$ into $R'$.
An ordered set of $(A, R, R')$ forms a data point in this model. There are $|G|^3 = 729$ outcomes in the entire sample space.

$R'$ is conditional on its previous state $R$ and the agent stone $A$, as shown in Figure~\ref{model}
The joint distribution of $P(a, r, r') = P(r'|r)P(r)P(r'|a)P(a)$\footnote{
	Lazy notation P(a) stands for P(A=a).
}.

Let's use $\theta$ to refer to the parameterization representing agent stone $A$'s causal power. Hence, the task to infer agent stone's causal power is to infer parameter $\theta$ given observed data points.

\subsection*{Causal power}

Causal power $\theta$ is given by a function $f(A, R) = R'$, stating that given an agent stone $A$ and recipient $R$, $R$ changes into $R'$. In other words,

\begin{equation}\label{pdf}
	P(a, r, r'|\theta) =
	\begin{cases}
		1 &\text{if } f_{\theta}(a, r) = r'\\
		0 &\text{otherwise}
	\end{cases}
\end{equation}

To better capture the uncertainty of real life, we use a softmax over Equation~(\ref{pdf}) to smooth out the cutoffs. Given $A, R$, there are 9 possible $R'$s, hence set $b=e^9$ as the base for this specific softmax, yielding

\begin{equation}\label{spdf}
	P(a, r, r'|\theta) =
	\begin{cases}
		.992 &\text{if } f_{\theta}(a, r) = r'\\
		.001 &\text{otherwise}
	\end{cases}
\end{equation}

\subsection*{Bayesian update}

In a standard Bayesian context, causal power functions form the hypothesis space $H$. During the \emph{learning} phase, the posterior distribution of causal power functions given data is calculated by:

\begin{equation}\label{learning}
	P(h|D) = \frac{P(D|h)P(h)}{\sum_{h_i \in H}P(D|h_i)P(h_i)}
\end{equation}	


While \emph{generalizing}, the posterior predictive distribution is given by marginalizing the distribution of new data $\tilde{d}$ over the posterior distribution ($Z$ is the normalizing factor):

\begin{equation}\label{gen}
	P(\tilde{d}|D) = Z \sum_{h\in H}P(\tilde{d}|h)P(h|D)
\end{equation}


\subsection*{Hierarchical Bayesian models}

% Figure for hierarchical Bayesian model framework
\tikzstyle{node} = [ellipse, minimum width=1.62cm, minimum height=0.8cm, text centered, draw=black]
\tikzstyle{box} = [rectangle, minimum width=2.4cm, minimum height=3cm, text centered, draw=black]
\tikzstyle{arrow} = [thick,->,>=stealth]
\begin{wrapfigure}{r}{0.25\textwidth}
\begin{center}
	\begin{tikzpicture}
		\node (ts) [node] {$T$};
		\node (hs) [node, below of=ts, yshift=-0.5cm] {$H$};
		\node (d) [node, below of=hs, yshift=-0.5cm] {$D$};
		\node (b) [box, below of=ts, yshift=-1.3cm] {};
		\draw [arrow] (ts) -- (hs);
		\draw [arrow] (hs) -- (d);
	\end{tikzpicture}
	\caption{A HBM.}
	\label{hbm}
\end{center}
\end{wrapfigure}

What causal power functions people may inspect forms the key part of this model. We follow a hierarchical Bayesian model (HBM) framework to tackle this problem.

The HBM we consider here consists of three levels of abstractions. As illustrated in Figure~\ref{hbm}, at the highest level of abstraction is theory space $T$, and each theory $t \in T$ generates some causal power functions, forming theory $t$'s hypothesis space $H_t$. Hypotheses generate data $D$, at the lowest level of abstraction in this framework.

Under this framework, theories are learned via:

\begin{equation}
P(t|D) \propto \sum_{h_t \in H_t}P(h_t|D)P(h_t|t)P(t)
\end{equation}

And generalization to new data point $\tilde{d}$ with posterior belief about theories is

\begin{equation}
P(\tilde{d}|D) \propto \sum_{t \in T}\sum_{h_t \in H_t}P(\tilde{d}|h_t)P(h_t|t)P(t)
\end{equation}



\subsubsection*{Candidate theories}

% Figure for candidate theory space
\tikzstyle{node} = [draw=none,fill=none, text centered]
\tikzstyle{box} = [fill=gray!30, minimum width=1.5cm, minimum height=5cm]
\tikzstyle{arrow} = [->,>=stealth]
\begin{wrapfigure}{l}{0.3\textwidth}
\begin{center}
	\begin{tikzpicture}
		\node (c) [box] {};
		\node (ct) [node, below of=c, yshift=3cm] {Causes};

		\node (e) [box, left of=c, xshift=3.4cm] {};
		\node (et) [node, below of=e, yshift=3cm] {Effects};
		
		\node (c1) [node, below of=c, yshift=2cm] {$object$};
		\node (c2) [node, below of=c1, yshift=-0.5cm] {$color$};
		\node (c3) [node, below of=c2, yshift=-0.5cm] {$shape$};
		
		\node (e1) [node, right of=c1, xshift=1.5cm] {$object$};
		\node (e2) [node, below of=e1, yshift=-0.5cm] {$color$};
		\node (e3) [node, below of=e2, yshift=-0.5cm] {$shape$};
		
		\draw [arrow] (c1) -- (e1);
		\draw [arrow] (c1) -- (e2);
		\draw [arrow] (c1) -- (e3);
		\draw [arrow] (c2) -- (e1);
		\draw [arrow] (c2) -- (e2);
		\draw [arrow] (c2) -- (e3);
		\draw [arrow] (c3) -- (e1);
		\draw [arrow] (c3) -- (e2);
		\draw [arrow] (c3) -- (e3);
	\end{tikzpicture}
	\caption{Formation space for $f$.}
	\label{form}
\end{center}
\end{wrapfigure}

A causal power function deals with cause conditions, and defines what effects will take place. Both a specific object, or an abstract feature, can serve as a cause condition. Similarly, an effect is to change a stone into a specific state (another object), or change one of its features. (Changing both features is the same as changing to a specific object.)


Different arrow combinations in Figure~\ref{form} generates different sets of causal power functions. For example, take the arrow $object \rightarrow object$, it generates $|G|^2 = 81$ possible causal power functions. One of these functions is $f_1((red \wedge square), R) = (red \wedge square)$, meaning that if an agent stone is of color $red$ and shape $square$, the recipient stone will turn into color $red$ and shape $squre$.

One example of a feature-level arrow is $color \rightarrow shape$. This generates $|\colorspace|\times|\shapespace|=9$ possible causal power functions. One of such functions is $f((red, s_A), R) = (c_{R'}, square)$, meaning that a $red$ agent stone, regardless of its shape, changes the recipient stone to shape $square$ and keeps its original color.

Table~\ref{functions} shows the number of total causal power functions these arrows produce. We treat each of these arrow as a \emph{theory}, and take all the possible causal power functions generated by all the theories as the complete hypothesis space $H$. Let $\mathbf{z}$ be a vector of 255 elements, for each $z_i \in \mathbf{z}$, $z_i = 1$ if $h_i \in H_t$, and $z_i = 0$ if $h_i \not \in H_t$. The prior probability of a theory generates a hypothesis $P(h|t)$ is therefore defined as a softmax over $\mathbf{z}$:

\begin{equation}
	P(h) = \sigma(\mathbf{z})
\end{equation}



\begin{table}[]
	\centering
	\begin{tabular}{rrrrrrrrrr}
		Arrow & $o \rightarrow o$ & $o \rightarrow c$ & $o \rightarrow s$ & $c \rightarrow o$ & $c \rightarrow c$ & $c \rightarrow s$ & $s \rightarrow o$ & $s \rightarrow c$ & $s \rightarrow s$ \\
		\hline \hline
		$|f|$ & 81  & 27  & 27  & 27  & 9   & 9   & 27  & 9   & 9   \\
		\hline
		Total &     &     &     &     &     &     &     &     & 225
	\end{tabular}
	\caption{Number of causal power functions each arrow combination produces. $o$: $object$, $c$: $color$, $s$:$shape$.}
	\label{functions}
\end{table}

\subsection*{Example}

\subsubsection*{Experiment}

Consider the following tasks

\textbf{Learning task 1}: $red$ $triangle$ changes $yellow$ $square$ to $red$ $square$.

\textbf{Generalization task 1.1}: $red$ $triangle$ changes $blue$ $circle$ to $?$

\textbf{Generalization task 1.2}: $red$ $square$ changes $blue$ $circle$ to $?$

\vspace*{1em}

\noindent
In addition to learning task 1:

\textbf{Learning task 2}: $red$ $circle$ changes $yellow$ $square$ to $red$ $square$.

\textbf{Generalization task 2.1}: $red$ $circle$ changes $blue$ $triangle$ to $?$

\textbf{Generalization task 2.2}: $red$ $square$ changes $blue$ $triangle$ to $?$

\subsubsection*{Model predictions}

As shown in Table~\ref{pred}. Lower case letters stand for $r$: red, $b$: blue, $y$: yellow, $c$: circle, $s$: square, $t$: triangle. Under `Task $n$' columns are the winning hypothesis under each theory, and under `Task $n.n$' columns are predicted data.

\begin{table}
	\centering
	\begin{tabular}{l|l|l|l|l|l|l|l}
		\multicolumn{2}{l|}{Conditions} & Task 1 & Task 1.1 & Task 1.2 & Task 2 & Task 2.1 & Task 2.2 \\
		\hline \hline
		Separate theories & $o \rightarrow o$ & $f((r, t), R) = (r,s)$ & $(r,s)$ & & & & \\
		& $o \rightarrow c$ & $f((r, t), R) = (r, R_s)$ & $(r,c)$ & & & & \\
		& $o \rightarrow s$ & $f((r, t), R) = (R_c, s)$ & $(b,s)$ & & & & \\
		& $c \rightarrow o$ & $f((r, A_s), R) = (r, s)$ & $(r,s)$ & $(r,s)$ & & & \\
		& $c \rightarrow c$ & $f((r, A_s), R) = (r, R_s)$ & $(r,c)$ & $(r,c)$ & $f((r, A_s), R) = (r, R_s)$ & $(r,c)$ & $(r,c)$ \\
		& $c \rightarrow s$ & $f((r, A_s), R) = (R_c, s)$ & $(b,s)$ & $(b,s)$ & $f((r, A_s), R) = (R_c, s)$ & $(b,s)$ & $(b,s)$ \\
		& $s \rightarrow o$ & $f((A_c, t), R) = (r, s)$ & $(r,s)$ & & $f((A_c, c), R) = (r, s)$ & $(r, s)$ & \\
		& $s \rightarrow c$ & $f((A_c, t), R) = (r, R_s)$ & $(r,c)$ & & $f((A_c, c), R) = (r, R_s)$ & $(r, t)$ & \\
		& $s \rightarrow s$ & $f((A_c, t), R) = (R_c, s)$ & $(b,s)$ & & $f((A_c, c), R) = (R_c, s)$ & $(b, s)$ & \\
		\hline
		\multicolumn{2}{l|}{Entire theory space} & & & & & & \\
		\hline
		\multicolumn{2}{l|}{Sub theory space?} & & & & & & \\
	\end{tabular}
	\caption{Model predictions for sample experiment.}
	\label{pred}
\end{table}

\section{Limitations}

\begin{enumerate}
	\item Cannot account for non-observed changes.
	\item Ignore recipient influence.
\end{enumerate}

\section{Alternatives}

Code it in a neural net (input-output pairs) and compare the results.








\end{document}